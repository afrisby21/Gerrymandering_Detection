{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import csv\n",
    "import os\n",
    "from functools import partial\n",
    "import json\n",
    "from math import pi, sqrt, nan\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gerrychain import (\n",
    "    Election,\n",
    "    Graph,\n",
    "    MarkovChain,\n",
    "    Partition,\n",
    "    accept,\n",
    "    constraints,\n",
    "    updaters,\n",
    ")\n",
    "from gerrychain.metrics import (efficiency_gap, \n",
    "    mean_median, \n",
    "    wasted_votes, \n",
    "    polsby_popper,\n",
    "    partisan_bias,\n",
    "    partisan_gini\n",
    ")\n",
    "from gerrychain.proposals import recom\n",
    "from gerrychain.updaters import (\n",
    "    Tally,\n",
    "    boundary_nodes,\n",
    "    cut_edges,\n",
    "    cut_edges_by_part,\n",
    "    exterior_boundaries,\n",
    "    interior_boundaries,\n",
    "    perimeter,\n",
    ")\n",
    "\n",
    "from gerrytools.scoring import reock\n",
    "\n",
    "# create output folder\n",
    "newdir = \"./Outputs/\"\n",
    "os.makedirs(os.path.dirname(newdir + \"init.txt\"), exist_ok=True)\n",
    "with open(newdir + \"init.txt\", \"w\") as f:\n",
    "    f.write(\"Created Folder\")\n",
    "\n",
    "# set paths\n",
    "graph_path = \"./Data/PA_VTDALL.json\" \n",
    "plot_path = \"./Data/VTD_FINAL.shp\"\n",
    "\n",
    "# load geopandas dataframe\n",
    "df = gpd.read_file(plot_path)\n",
    "df['GEOID10_copy'] = df['GEOID10']\n",
    "\n",
    "df = df.set_index('GEOID10_copy')\n",
    "\n",
    "# helper functions\n",
    "def num_splits(partition):\n",
    "    \"\"\"\n",
    "    Computes the number of district splits within a given partition.\n",
    "\n",
    "    Paramters: \n",
    "        partition: GerryChain Partition - generated districting plan in current step\n",
    "\n",
    "    return: \n",
    "        int - number of splits\n",
    "    \"\"\"\n",
    "\n",
    "    df[\"current\"] = df[unique_label].map(dict(partition.assignment))\n",
    "    splits = sum(df.groupby(\"COUNTYFP10\")[\"current\"].nunique() > 1)\n",
    "    return splits\n",
    "\n",
    "def custom_eff_gap(total_votes, wasted1, wasted2):\n",
    "    \"\"\"\n",
    "    Computes the efficiency gap score (EGS) for a single district.\n",
    "\n",
    "    Paramters: \n",
    "        total_votes: int - number of total votes in election\n",
    "        wasted1: int - number of wasted votes for party 1 in election\n",
    "        wasted2: int - number of wasted votes for party 2 in election\n",
    "\n",
    "    return: \n",
    "        float - EGS value\n",
    "    \"\"\"\n",
    "    return (wasted2 - wasted1) / total_votes\n",
    "\n",
    "def compute_schwartz(area, perimeter):\n",
    "    \"\"\"\n",
    "    Function that actually computes the Schwartzberg compactness score for a district in a partition.\n",
    "\n",
    "    Paramters: \n",
    "        area: float - area of district\n",
    "        perimeter: float - perimeter of district\n",
    "\n",
    "    return: \n",
    "        float - Schwartzberg compactness score\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return 1/(perimeter/(2*pi*sqrt(area/pi)))\n",
    "    except ZeroDivisionError:\n",
    "        return nan\n",
    "\n",
    "def schwartz(partition):\n",
    "    \"\"\"\n",
    "    Compiles Schwartzberg compactness scores for each district in the partition.\n",
    "\n",
    "    Paramters: \n",
    "        partition: GerryChain Partition - generated districting plan in current step\n",
    "\n",
    "    return: \n",
    "        dict - dictionary where the keys are the districts and the values are the schwartzberg scores\n",
    "    \"\"\"\n",
    "    return {\n",
    "        part: compute_schwartz(\n",
    "            partition[\"area\"][part], partition[\"perimeter\"][part]\n",
    "        )\n",
    "        for part in partition.parts\n",
    "    }\n",
    "\n",
    "def flatten(lst):\n",
    "    \"\"\"\n",
    "    Flattens a list of lists to a single list.\n",
    "\n",
    "    Paramters: \n",
    "        lst: list - list of lists to be flattened\n",
    "\n",
    "    return: \n",
    "        list - flattened list\n",
    "    \"\"\"\n",
    "    return [[item] for sublist in lst for item in sublist]\n",
    "\n",
    "# set unique label\n",
    "unique_label = \"GEOID10\"\n",
    "\n",
    "# define elections\n",
    "num_elections = 9\n",
    "\n",
    "election_names = [\n",
    "    \"ATG12\",\n",
    "    \"GOV14\",\n",
    "    \"GOV10\",\n",
    "    \"PRES12\",\n",
    "    \"SEN10\",\n",
    "    \"ATG16\",\n",
    "    \"PRES16\",\n",
    "    \"SEN16\",\n",
    "    \"SEN12\"\n",
    "]\n",
    "election_columns = [\n",
    "    [\"ATG12D\", \"ATG12R\"],\n",
    "    [\"F2014GOVD\", \"F2014GOVR\"],\n",
    "    [\"GOV10D\", \"GOV10R\"],\n",
    "    [\"PRES12D\", \"PRES12R\"],\n",
    "    [\"SEN10D\", \"SEN10R\"],\n",
    "    [\"T16ATGD\", \"T16ATGR\"],\n",
    "    [\"T16PRESD\", \"T16PRESR\"],\n",
    "    [\"T16SEND\", \"T16SENR\"],\n",
    "    [\"USS12D\", \"USS12R\"]\n",
    "]\n",
    "\n",
    "# create graph object from json file\n",
    "graph = Graph.from_json(graph_path)\n",
    "graph.join(df, columns=['geometry'])\n",
    "\n",
    "# create updaters for Markov chain to track each iteration\n",
    "updaters = {\n",
    "    \"population\": Tally(\"TOT_POP\", alias=\"population\"),\n",
    "    \"cut_edges\": cut_edges,\n",
    "    \"non_black_pop\": Tally(\"nBPOP\", alias='non_black_pop'),\n",
    "    'black_pop': Tally('BPOP', alias='black_pop'),\n",
    "    'area': Tally('areas', alias='area'),\n",
    "    \"perimeter\": perimeter,\n",
    "    \"exterior_boundaries\": exterior_boundaries,\n",
    "    \"interior_boundaries\": interior_boundaries,\n",
    "    \"boundary_nodes\": boundary_nodes,\n",
    "    \"cut_edges_by_part\": cut_edges_by_part,\n",
    "    'reock': reock(graph)\n",
    "}\n",
    "\n",
    "elections = [\n",
    "    Election(\n",
    "        election_names[i],\n",
    "        {\"Democratic\": election_columns[i][0], \"Republican\": election_columns[i][1]},\n",
    "    )\n",
    "    for i in range(num_elections)\n",
    "]\n",
    "\n",
    "election_updaters = {election.name: election for election in elections}\n",
    "\n",
    "updaters.update(election_updaters)\n",
    "\n",
    "# define starting plan/partition \n",
    "# select initial plan: '2011_PLA_1', '538CPCT__1', 'REMEDIAL_P'\n",
    "initial_partition = Partition(graph, 'REMEDIAL_P', updaters)\n",
    "\n",
    "# set population boundaries for each district\n",
    "ideal_population = sum(initial_partition[\"population\"].values()) / len(\n",
    "    initial_partition\n",
    ")\n",
    "\n",
    "proposal = partial(\n",
    "    recom, pop_col=\"TOT_POP\", pop_target=ideal_population, epsilon=0.02, node_repeats=2\n",
    ")\n",
    "\n",
    "# set compactness constraint for each district\n",
    "compactness_bound = constraints.UpperBound(\n",
    "    lambda p: len(p[\"cut_edges\"]), 4 * len(initial_partition[\"cut_edges\"])\n",
    ")\n",
    "\n",
    "\n",
    "# create Markov chain with previously defined parameters/constraints\n",
    "chain = MarkovChain(\n",
    "    proposal=proposal,\n",
    "    constraints=[\n",
    "        constraints.within_percent_of_ideal_population(initial_partition, 0.02),\n",
    "        compactness_bound, \n",
    "    ],\n",
    "    accept=accept.always_accept,\n",
    "    initial_state=initial_partition,\n",
    "    total_steps=10000 # total steps of Markov chain\n",
    ")\n",
    "\n",
    "# initialize features and metrics to track during Markov chain\n",
    "pop_vec = []\n",
    "wpop_vec = []\n",
    "bpop_vec = []\n",
    "cut_vec = []\n",
    "area_vec = []\n",
    "perim_vec = []\n",
    "\n",
    "mms = []\n",
    "dist_mms = []\n",
    "egs = []\n",
    "part_bias = []\n",
    "part_gini = []\n",
    "dist_egs = []\n",
    "dist_polsby = []\n",
    "dist_reock = []\n",
    "dist_schwartz = []\n",
    "hmss = []\n",
    "\n",
    "splits = []\n",
    "\n",
    "dist_egs_master = []\n",
    "dist_mms_master = []\n",
    "\n",
    "# define chain/loop parameters\n",
    "t = 0\n",
    "t_step = 10\n",
    "dist_loop = False\n",
    "statewide = True\n",
    "\n",
    "# color of generated districts\n",
    "color = 'blue'\n",
    "\n",
    "\n",
    "# loop through Markov chain\n",
    "for part in chain:\n",
    "\n",
    "    t += 1\n",
    "    # generate/append images/data after every t_step versions of the map\n",
    "    if t % t_step == 0:\n",
    "        print(t)\n",
    "\n",
    "        pop_vec.append(list(part[\"population\"].values()))\n",
    "        wpop_vec.append(list(part[\"non_black_pop\"].values()))\n",
    "        bpop_vec.append(list(part[\"black_pop\"].values()))\n",
    "        cut_vec.append(len(part[\"cut_edges\"]))\n",
    "        area_vec.append(list(part['area'].values()))\n",
    "        perim_vec.append(list(part['perimeter'].values()))\n",
    "\n",
    "\n",
    "        if statewide:\n",
    "\n",
    "            mms.append([])\n",
    "            egs.append([])\n",
    "            hmss.append([])\n",
    "            part_bias.append([])\n",
    "            part_gini.append([])\n",
    "\n",
    "            for elect in range(num_elections):\n",
    "                mms[-1].append(mean_median(part[election_names[elect]]))\n",
    "                egs[-1].append(efficiency_gap(part[election_names[elect]]))\n",
    "                part_bias[-1].append(partisan_bias(part[election_names[elect]]))\n",
    "                part_gini[-1].append(partisan_gini(part[election_names[elect]]))\n",
    "                hmss[-1].append(part[election_names[elect]].wins(\"Democratic\"))\n",
    "        \n",
    "            # generate and save statewide map\n",
    "            df[\"plot\" + str(t)] = df.index.map(part.assignment)\n",
    "            df.plot(column=\"plot\" + str(t), cmap=\"tab20\").axis('off')\n",
    "            plt.savefig(newdir +'images/statewide/' + \"state_plot\" + str(t) + \".png\")\n",
    "            plt.close()\n",
    "            df.drop(columns=[\"plot\" + str(t)], inplace=True)\n",
    "\n",
    "        # calculate and append compactness metrics\n",
    "        dist_polsby.append(list(polsby_popper(part).values()))\n",
    "\n",
    "        dist_schwartz.append(list(schwartz(part).values()))\n",
    "\n",
    "        dist_reock.append(list(part['reock'].values()))\n",
    "\n",
    "        # district generation loop\n",
    "        if dist_loop:\n",
    "\n",
    "            # do similar thing as statewide, but loop through every district\n",
    "            dist_egs_master.append([])\n",
    "            dist_mms_master.append([])\n",
    "            \n",
    "            for counter, district in enumerate(part.assignment.parts.keys()): \n",
    "\n",
    "                # create dict for specific district in loop and map it to geodataframe \n",
    "                dist_geo_dict = {key:val for key, val in part.assignment.items() if val == district}\n",
    "\n",
    "                df['plot' + str(int(t/t_step)) + str(district)] = df['GEOID10'].map(dist_geo_dict)\n",
    "\n",
    "                # generate and save each district, set cmap for color\n",
    "                    # 'Set1' for red \n",
    "                    # 'Dark2' for green\n",
    "                    # 'tab20' for blue\n",
    "                df.plot(column=\"plot\" + str(int(t/t_step)) + str(district), cmap=\"tab20\").axis('off')\n",
    "                plt.savefig(newdir + f'images/{color}/' + \"plot\" + str(int(t/t_step)) + 'd' + str(district) + \".png\")\n",
    "                plt.close()\n",
    "                df.drop(columns=['plot' + str(int(t/t_step)) + str(district)], inplace=True)\n",
    "                dist_geo_dict.clear()\n",
    "\n",
    "                # calculate and append district-level metrics \n",
    "                dist_egs.append([])\n",
    "                dist_mms.append([])\n",
    "\n",
    "                uid = str(int(t/t_step)) + 'd' + str(district)\n",
    "\n",
    "                dist_egs[-1].append(uid)\n",
    "                dist_mms[-1].append(uid)\n",
    "\n",
    "                # loop through each election to calculate EGS value for each district \n",
    "                for elect in range(num_elections):\n",
    "                    \n",
    "                    dem_votes = part[election_names[elect]].counts('Democratic')[counter]\n",
    "                    rep_votes = part[election_names[elect]].counts('Republican')[counter]\n",
    "                    total_votes = dem_votes + rep_votes\n",
    "\n",
    "                    wasted_votes_dem, wasted_votes_rep = wasted_votes(dem_votes, rep_votes)\n",
    "\n",
    "                    dist_egs[-1].append(custom_eff_gap(total_votes, wasted_votes_dem, wasted_votes_rep))\n",
    "            \n",
    "                \n",
    "                dist_egs_master.append(dist_egs[-1])\n",
    "                dist_mms_master.append(dist_mms[-1])\n",
    "                \n",
    "                # reset lists for next iteration\n",
    "                dist_egs = []\n",
    "                dist_mms = []\n",
    "\n",
    "        # save files every 1000 steps in case of memory failure\n",
    "        if t % 1000 == 0:\n",
    "            with open(newdir + \"master_egs\" + \".csv\", \"w\") as tf1:\n",
    "                writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "                writer.writerows(dist_egs_master)\n",
    "\n",
    "            with open(newdir + \"master_polsby\" + \".csv\", \"w\") as tf1:\n",
    "                writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "                writer.writerows(flatten(dist_polsby))\n",
    "\n",
    "            with open(newdir + \"master_schwartz\" + \".csv\", \"w\") as tf1:\n",
    "                writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "                writer.writerows(flatten(dist_schwartz))\n",
    "\n",
    "            with open(newdir + \"master_reock\" + \".csv\", \"w\") as tf1:\n",
    "                writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "                writer.writerows(flatten(dist_reock))\n",
    "\n",
    "            with open(newdir + \"mms\" + \".csv\", \"w\") as tf1:\n",
    "                writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "                writer.writerows(mms)\n",
    "\n",
    "            with open(newdir + \"master_mms\" + \".csv\", \"w\") as tf1:\n",
    "                writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "                writer.writerows(dist_mms_master)\n",
    "\n",
    "            with open(newdir + \"egs\" + \".csv\", \"w\") as tf1:\n",
    "                writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "                writer.writerows(egs)\n",
    "\n",
    "            with open(newdir + \"partisan_bias\" + \".csv\", \"w\") as tf1:\n",
    "                writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "                writer.writerows(part_bias)\n",
    "\n",
    "            with open(newdir + \"partisan_gini\" + \".csv\", \"w\") as tf1:\n",
    "                writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "                writer.writerows(part_gini)\n",
    "\n",
    "            with open(newdir + \"hmss\" + \".csv\", \"w\") as tf1:\n",
    "                writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "                writer.writerows(hmss)\n",
    "\n",
    "            with open(newdir + \"pop\" + \".csv\", \"w\") as tf1:\n",
    "                writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "                writer.writerows(flatten(pop_vec))\n",
    "\n",
    "            with open(newdir + \"areas\" + \".csv\", \"w\") as tf1:\n",
    "                writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "                writer.writerows(flatten(area_vec))\n",
    "\n",
    "            with open(newdir + \"white_pop\" + \".csv\", \"w\") as tf1:\n",
    "                writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "                writer.writerows(flatten(wpop_vec))\n",
    "\n",
    "            with open(newdir + \"black_pop\" + \".csv\", \"w\") as tf1:\n",
    "                writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "                writer.writerows(flatten(bpop_vec))\n",
    "\n",
    "            with open(newdir + \"perimeters\" + \".csv\", \"w\") as tf1:\n",
    "                writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "                writer.writerows(flatten(perim_vec))\n",
    "\n",
    "\n",
    "# save files after Markov chain is done\n",
    "with open(newdir + \"master_egs\" + \".csv\", \"w\") as tf1:\n",
    "    writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "    writer.writerows(dist_egs_master)\n",
    "\n",
    "with open(newdir + \"master_polsby\" + \".csv\", \"w\") as tf1:\n",
    "    writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "    writer.writerows(flatten(dist_polsby))\n",
    "\n",
    "with open(newdir + \"master_schwartz\" + \".csv\", \"w\") as tf1:\n",
    "    writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "    writer.writerows(flatten(dist_schwartz))\n",
    "\n",
    "with open(newdir + \"master_reock\" + \".csv\", \"w\") as tf1:\n",
    "    writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "    writer.writerows(flatten(dist_reock))\n",
    "\n",
    "with open(newdir + \"mms\" + \".csv\", \"w\") as tf1:\n",
    "    writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "    writer.writerows(mms)\n",
    "\n",
    "with open(newdir + \"egs\" + \".csv\", \"w\") as tf1:\n",
    "    writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "    writer.writerows(egs)\n",
    "\n",
    "with open(newdir + \"partisan_bias\" + \".csv\", \"w\") as tf1:\n",
    "    writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "    writer.writerows(part_bias)\n",
    "\n",
    "with open(newdir + \"partisan_gini\" + \".csv\", \"w\") as tf1:\n",
    "    writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "    writer.writerows(part_gini)\n",
    "\n",
    "with open(newdir + \"hmss\" + \".csv\", \"w\") as tf1:\n",
    "    writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "    writer.writerows(hmss)\n",
    "\n",
    "with open(newdir + \"pop\" + \".csv\", \"w\") as tf1:\n",
    "    writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "    writer.writerows(flatten(pop_vec))\n",
    "\n",
    "with open(newdir + \"areas\" + \".csv\", \"w\") as tf1:\n",
    "    writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "    writer.writerows(flatten(area_vec))\n",
    "\n",
    "with open(newdir + \"white_pop\" + \".csv\", \"w\") as tf1:\n",
    "    writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "    writer.writerows(flatten(wpop_vec))\n",
    "\n",
    "with open(newdir + \"black_pop\" + \".csv\", \"w\") as tf1:\n",
    "    writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "    writer.writerows(flatten(bpop_vec))\n",
    "\n",
    "with open(newdir + \"perimeters\" + \".csv\", \"w\") as tf1:\n",
    "    writer = csv.writer(tf1, lineterminator=\"\\n\")\n",
    "    writer.writerows(flatten(perim_vec))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Columns in initial geodataframe for reference when selecting/examining available elections, features, and starting districting plans: \n",
    "\n",
    "['STATEFP10', 'COUNTYFP10', 'VTDST10', 'GEOID10', 'VTDI10', 'NAME10',\n",
    "       'NAMELSAD10', 'LSAD10', 'MTFCC10', 'FUNCSTAT10', 'ALAND10', 'AWATER10',\n",
    "       'INTPTLAT10', 'INTPTLON10', 'ATG12D', 'ATG12R', 'GOV10D', 'GOV10R',\n",
    "       'PRES12D', 'PRES12O', 'PRES12R', 'SEN10D', 'SEN10R', 'T16ATGD',\n",
    "       'T16ATGR', 'T16PRESD', 'T16PRESOTH', 'T16PRESR', 'T16SEND', 'T16SENR',\n",
    "       'USS12D', 'USS12R', 'GOV', 'TS', 'HISP_POP', 'TOT_POP', 'WHITE_POP',\n",
    "       'BLACK_POP', 'NATIVE_POP', 'ASIAN_POP', 'F2014GOVD', 'F2014GOVR',\n",
    "       '2011_PLA_1', 'REMEDIAL_P', '538CPCT__1', '538DEM_PL', '538GOP_PL',\n",
    "       '8THGRADE_1', '__ID', 'INT001', 'INT002', 'INT003', 'INT004', 'INT005',\n",
    "       'INT006', 'INT007', 'INT008', 'LG', 'W1012R', 'W1012D', 'W1016R',\n",
    "       'W1016D', 'W101216R', 'W101216D', 'W1216R', 'W1216D', 'CD', 'Lower',\n",
    "       'Upper', 'BPOP', 'nBPOP', 'geometry']\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order of districts for starting plan - does not change during Markov chain\n",
    "# for reference in later notebooks\n",
    "part.assignment.parts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "992af9430b13ada16c30f2ac47cf0d744148870fc875adc12e54130686e91185"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
